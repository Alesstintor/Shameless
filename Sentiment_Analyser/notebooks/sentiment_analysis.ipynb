{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Model Training for Kaggle\n",
    "\n",
    "**Objetivo:** Entrenar un modelo de an√°lisis de sentimientos que sea **agn√≥stico a la fuente de datos** y pueda analizar 1..n textos de entrada.\n",
    "\n",
    "**Workflow:**\n",
    "1. ‚öôÔ∏è **Training en Kaggle** ‚Üí GPU gratuita + datasets p√∫blicos\n",
    "2. üíæ **Export modelo** ‚Üí Guardar en Kaggle Dataset\n",
    "3. üè† **Deploy local** ‚Üí Descargar via Kaggle API y usar en producci√≥n\n",
    "\n",
    "**Caracter√≠sticas del modelo:**\n",
    "- ‚úÖ Acepta 1 o m√∫ltiples textos\n",
    "- ‚úÖ Independiente de la fuente (Twitter, texto gen√©rico, etc.)\n",
    "- ‚úÖ Optimizado para inferencia r√°pida\n",
    "- ‚úÖ F√°cil de exportar e importar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ML & NLP\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "MODEL_NAME = \"distilbert-base-uncased\"  # Fast and efficient\n",
    "MODEL_VERSION = \"v1.0\"\n",
    "MAX_LENGTH = 128  # Token length for tweets/short texts\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "EPOCHS = 3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Data Configuration\n",
    "DATASET_NAME = \"sentiment140\"  # Change to your dataset in Kaggle\n",
    "TRAIN_SIZE = 0.8\n",
    "VAL_SIZE = 0.1\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "# Output Configuration\n",
    "OUTPUT_DIR = \"./shameless_sentiment_model\"\n",
    "SAVE_TO_KAGGLE = True  # Set to True to save as Kaggle Dataset\n",
    "\n",
    "print(f\"ü§ñ Model: {MODEL_NAME}\")\n",
    "print(f\"üéØ Device: {DEVICE}\")\n",
    "print(f\"üìä Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"üîÑ Epochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 1: Load Dataset\n",
    "\n",
    "**Nota:** En Kaggle, usa datasets p√∫blicos como Sentiment140, Twitter Sentiment Analysis, etc.\n",
    "Este c√≥digo es **agn√≥stico** - funciona con cualquier dataset que tenga columnas 'text' y 'sentiment'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Loading Sentiment140 dataset (modify path for Kaggle)\n",
    "# In Kaggle, use: /kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv\n",
    "\n",
    "def load_sentiment140_sample():\n",
    "    \"\"\"\n",
    "    Load and prepare a sample dataset.\n",
    "    In Kaggle, replace this with actual dataset loading.\n",
    "    \"\"\"\n",
    "    # For demonstration - create sample data\n",
    "    # In Kaggle: df = pd.read_csv('/kaggle/input/sentiment140/...', encoding='latin-1')\n",
    "    \n",
    "    sample_data = {\n",
    "        'text': [\n",
    "            \"I love this product! It's amazing!\",\n",
    "            \"This is terrible, worst experience ever\",\n",
    "            \"Not sure how I feel about this\",\n",
    "            \"Absolutely fantastic, highly recommend\",\n",
    "            \"Disappointed with the quality\",\n",
    "            \"Pretty decent, nothing special\",\n",
    "            \"Outstanding service and support!\",\n",
    "            \"Waste of money, do not buy\",\n",
    "            \"It's okay, works as expected\",\n",
    "            \"Best purchase I've ever made!\"\n",
    "        ],\n",
    "        'sentiment': [1, 0, 1, 1, 0, 1, 1, 0, 1, 1]  # 1=positive, 0=negative\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(sample_data)\n",
    "\n",
    "# Load data\n",
    "print(\"üì• Loading dataset...\")\n",
    "df = load_sentiment140_sample()\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded: {len(df)} samples\")\n",
    "print(f\"\\nDataset structure:\")\n",
    "print(df.head())\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üîÑ Step 2: Data Preprocessing\n",
    "\n",
    "Crear un dataset PyTorch **agn√≥stico** que funcione con cualquier texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset agn√≥stico para an√°lisis de sentimientos.\n",
    "    Funciona con cualquier texto de entrada (tweets, reviews, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Dataset class created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "print(\"üìä Splitting dataset...\")\n",
    "\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df['text'].values,\n",
    "    df['sentiment'].values,\n",
    "    test_size=(VAL_SIZE + TEST_SIZE),\n",
    "    random_state=42,\n",
    "    stratify=df['sentiment'].values\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts,\n",
    "    temp_labels,\n",
    "    test_size=TEST_SIZE/(VAL_SIZE + TEST_SIZE),\n",
    "    random_state=42,\n",
    "    stratify=temp_labels\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Train: {len(train_texts)}, Val: {len(val_texts)}, Test: {len(test_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "print(f\"üî§ Loading tokenizer: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
    "val_dataset = SentimentDataset(val_texts, val_labels, tokenizer, MAX_LENGTH)\n",
    "test_dataset = SentimentDataset(test_texts, test_labels, tokenizer, MAX_LENGTH)\n",
    "\n",
    "print(\"‚úÖ Datasets created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Step 3: Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "print(f\"ü§ñ Loading model: {MODEL_NAME}\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,  # Binary classification: positive/negative\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "model.to(DEVICE)\n",
    "print(f\"‚úÖ Model loaded on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 4: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    fp16=torch.cuda.is_available(),  # Mixed precision if GPU available\n",
    ")\n",
    "\n",
    "# Define metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {'accuracy': acc, 'f1': f1}\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üèãÔ∏è Step 5: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üèãÔ∏è Starting training...\")\n",
    "start_time = datetime.now()\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "end_time = datetime.now()\n",
    "training_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed!\")\n",
    "print(f\"‚è±Ô∏è Training time: {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "print(f\"üìä Final metrics: {train_result.metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 6: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"üìä Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(f\"\\nüéØ Test Results:\")\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions for detailed analysis\n",
    "print(\"üîç Getting predictions for detailed analysis...\")\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = predictions.predictions.argmax(-1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    pred_labels,\n",
    "    target_names=['Negative', 'Positive']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üß™ Step 7: Test with Sample Texts (Data-Agnostic)\n",
    "\n",
    "Probar el modelo con 1..n textos de cualquier fuente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inference pipeline\n",
    "print(\"üîÆ Creating inference pipeline...\")\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if DEVICE == \"cuda\" else -1\n",
    ")\n",
    "\n",
    "# Test with single text\n",
    "single_text = \"I absolutely love this! Best thing ever!\"\n",
    "result = sentiment_pipeline(single_text)[0]\n",
    "print(f\"\\n‚úÖ Single text prediction:\")\n",
    "print(f\"Text: {single_text}\")\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# Test with multiple texts (1..n texts)\n",
    "multiple_texts = [\n",
    "    \"This is amazing, highly recommend!\",\n",
    "    \"Terrible experience, very disappointed\",\n",
    "    \"Not bad, could be better\",\n",
    "    \"Absolutely fantastic product!\",\n",
    "    \"Waste of time and money\"\n",
    "]\n",
    "\n",
    "print(f\"\\n‚úÖ Multiple texts prediction ({len(multiple_texts)} texts):\")\n",
    "results = sentiment_pipeline(multiple_texts)\n",
    "for text, result in zip(multiple_texts, results):\n",
    "    print(f\"Text: {text[:50]}...\")\n",
    "    print(f\"Result: {result['label']} (confidence: {result['score']:.4f})\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 8: Save Model for Production\n",
    "\n",
    "Guardar el modelo entrenado para ser usado localmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model directory\n",
    "output_path = Path(OUTPUT_DIR) / MODEL_VERSION\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üíæ Saving model to: {output_path}\")\n",
    "\n",
    "# Save model and tokenizer\n",
    "model.save_pretrained(output_path / \"model\")\n",
    "tokenizer.save_pretrained(output_path / \"tokenizer\")\n",
    "\n",
    "# Save configuration and metrics\n",
    "config = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"model_version\": MODEL_VERSION,\n",
    "    \"max_length\": MAX_LENGTH,\n",
    "    \"num_labels\": 2,\n",
    "    \"label_mapping\": {0: \"negative\", 1: \"positive\"},\n",
    "    \"training_date\": datetime.now().isoformat(),\n",
    "    \"training_time_seconds\": training_time,\n",
    "    \"device_used\": DEVICE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"learning_rate\": LEARNING_RATE\n",
    "}\n",
    "\n",
    "with open(output_path / \"config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    \"test_accuracy\": float(test_results.get(\"eval_accuracy\", 0)),\n",
    "    \"test_f1\": float(test_results.get(\"eval_f1\", 0)),\n",
    "    \"test_loss\": float(test_results.get(\"eval_loss\", 0)),\n",
    "    \"train_loss\": float(train_result.metrics.get(\"train_loss\", 0)),\n",
    "    \"classification_report\": classification_report(\n",
    "        true_labels, pred_labels, \n",
    "        target_names=['Negative', 'Positive'],\n",
    "        output_dict=True\n",
    "    )\n",
    "}\n",
    "\n",
    "with open(output_path / \"metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Model saved successfully!\")\n",
    "print(f\"\\nSaved files:\")\n",
    "print(f\"  - {output_path / 'model'}\")\n",
    "print(f\"  - {output_path / 'tokenizer'}\")\n",
    "print(f\"  - {output_path / 'config.json'}\")\n",
    "print(f\"  - {output_path / 'metrics.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 9: Package for Kaggle Dataset (Optional)\n",
    "\n",
    "Si est√°s en Kaggle, crea un dataset con el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create README for the model\n",
    "readme_content = f\"\"\"# Shameless Sentiment Model {MODEL_VERSION}\n",
    "\n",
    "## Model Information\n",
    "- **Base Model**: {MODEL_NAME}\n",
    "- **Version**: {MODEL_VERSION}\n",
    "- **Training Date**: {datetime.now().strftime('%Y-%m-%d')}\n",
    "- **Task**: Binary Sentiment Classification (Positive/Negative)\n",
    "\n",
    "## Performance\n",
    "- **Test Accuracy**: {metrics['test_accuracy']:.4f}\n",
    "- **Test F1 Score**: {metrics['test_f1']:.4f}\n",
    "- **Test Loss**: {metrics['test_loss']:.4f}\n",
    "\n",
    "## Usage\n",
    "\n",
    "### In Kaggle\n",
    "1. Save this notebook's output as a Kaggle Dataset\n",
    "2. Make it public or private\n",
    "3. Note the dataset name (e.g., `username/shameless-sentiment-models`)\n",
    "\n",
    "### Download to Local\n",
    "```bash\n",
    "# Install Kaggle API\n",
    "pip install kaggle\n",
    "\n",
    "# Download dataset (replace with your dataset name)\n",
    "kaggle datasets download username/shameless-sentiment-models\n",
    "unzip shameless-sentiment-models.zip -d data/models/\n",
    "```\n",
    "\n",
    "### Load Model Locally\n",
    "```python\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"data/models/{MODEL_VERSION}/model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"data/models/{MODEL_VERSION}/tokenizer\")\n",
    "\n",
    "# Create pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Predict single text\n",
    "result = sentiment_analyzer(\"I love this product!\")\n",
    "print(result)  # [{{'label': 'LABEL_1', 'score': 0.99}}]\n",
    "\n",
    "# Predict multiple texts (data-agnostic: works with 1..n texts)\n",
    "texts = [\"Great product!\", \"Terrible experience\", \"Not bad\"]\n",
    "results = sentiment_analyzer(texts)\n",
    "print(results)\n",
    "```\n",
    "\n",
    "## Label Mapping\n",
    "- LABEL_0 = Negative\n",
    "- LABEL_1 = Positive\n",
    "\n",
    "## Training Configuration\n",
    "- Epochs: {EPOCHS}\n",
    "- Batch Size: {BATCH_SIZE}\n",
    "- Learning Rate: {LEARNING_RATE}\n",
    "- Max Length: {MAX_LENGTH} tokens\n",
    "- Device: {DEVICE}\n",
    "\n",
    "## Data-Agnostic Design\n",
    "This model is designed to be **source-agnostic**:\n",
    "- ‚úÖ Works with tweets\n",
    "- ‚úÖ Works with reviews\n",
    "- ‚úÖ Works with any short text\n",
    "- ‚úÖ Accepts 1 or multiple texts\n",
    "- ‚úÖ No preprocessing required (model handles it internally)\n",
    "\"\"\"\n",
    "\n",
    "with open(output_path / \"README.md\", \"w\") as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"‚úÖ README.md created\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üì¶ MODEL PACKAGE READY FOR KAGGLE DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTo create Kaggle Dataset:\")\n",
    "print(f\"1. In Kaggle, go to 'Data' ‚Üí 'New Dataset'\")\n",
    "print(f\"2. Upload the folder: {output_path}\")\n",
    "print(f\"3. Name it: 'shameless-sentiment-models'\")\n",
    "print(f\"4. Set visibility (public/private)\")\n",
    "print(f\"5. Click 'Create'\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè† Step 10: How to Use Model Locally\n",
    "\n",
    "Instrucciones para descargar y usar el modelo en tu aplicaci√≥n local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: How to integrate with local application\n",
    "integration_example = \"\"\"\n",
    "# ============================================================================\n",
    "# INTEGRATION WITH LOCAL APPLICATION (Shameless)\n",
    "# ============================================================================\n",
    "\n",
    "# 1. Download model from Kaggle Dataset\n",
    "# --------------------------------------\n",
    "# Command line:\n",
    "#   kaggle datasets download username/shameless-sentiment-models -p data/models/\n",
    "#   unzip data/models/shameless-sentiment-models.zip -d data/models/\n",
    "\n",
    "# 2. Create Model Loader (models/model_loader.py)\n",
    "# ------------------------------------------------\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "import json\n",
    "\n",
    "class KaggleModelLoader:\n",
    "    def __init__(self, models_dir=\"data/models\"):\n",
    "        self.models_dir = Path(models_dir)\n",
    "    \n",
    "    def load_model(self, version=\"v1.0\"):\n",
    "        model_path = self.models_dir / version / \"model\"\n",
    "        tokenizer_path = self.models_dir / version / \"tokenizer\"\n",
    "        config_path = self.models_dir / version / \"config.json\"\n",
    "        \n",
    "        # Load configuration\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        # Load model and tokenizer\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "        \n",
    "        # Create pipeline\n",
    "        sentiment_pipeline = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            device=-1  # CPU, use 0 for GPU\n",
    "        )\n",
    "        \n",
    "        return sentiment_pipeline, config\n",
    "\n",
    "# 3. Use in SentimentAnalyzer (models/inference/sentiment_analyzer.py)\n",
    "# ---------------------------------------------------------------------\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self, model_version=\"v1.0\", use_kaggle_model=True):\n",
    "        if use_kaggle_model:\n",
    "            loader = KaggleModelLoader()\n",
    "            self.pipeline, self.config = loader.load_model(model_version)\n",
    "            self.label_mapping = self.config.get(\"label_mapping\", {})\n",
    "        else:\n",
    "            # Use HuggingFace model\n",
    "            self.pipeline = pipeline(\"sentiment-analysis\")\n",
    "    \n",
    "    def analyze(self, text):\n",
    "        result = self.pipeline(text)[0]\n",
    "        return {\n",
    "            'sentiment': self.label_mapping.get(str(result['label']), result['label']),\n",
    "            'score': result['score']\n",
    "        }\n",
    "    \n",
    "    def analyze_batch(self, texts, batch_size=32):\n",
    "        # Data-agnostic: accepts 1..n texts\n",
    "        results = self.pipeline(texts, batch_size=batch_size)\n",
    "        return [\n",
    "            {\n",
    "                'sentiment': self.label_mapping.get(str(r['label']), r['label']),\n",
    "                'score': r['score']\n",
    "            }\n",
    "            for r in results\n",
    "        ]\n",
    "\n",
    "# 4. Use in application\n",
    "# ---------------------\n",
    "from sentiment_analyser.models import SentimentAnalyzer\n",
    "\n",
    "# Initialize with Kaggle model\n",
    "analyzer = SentimentAnalyzer(use_kaggle_model=True, model_version=\"v1.0\")\n",
    "\n",
    "# Analyze single text\n",
    "result = analyzer.analyze(\"I love this product!\")\n",
    "print(result)  # {'sentiment': 'positive', 'score': 0.99}\n",
    "\n",
    "# Analyze multiple texts (data-agnostic)\n",
    "tweets = [\"Great service!\", \"Terrible experience\", \"Not bad at all\"]\n",
    "results = analyzer.analyze_batch(tweets)\n",
    "for tweet, result in zip(tweets, results):\n",
    "    print(f\"{tweet}: {result['sentiment']} ({result['score']:.2f})\")\n",
    "\n",
    "# Works with ANY text source - tweets, reviews, comments, etc.\n",
    "\"\"\"\n",
    "\n",
    "print(integration_example)\n",
    "\n",
    "print(\"\\n‚úÖ Integration example ready!\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ NOTEBOOK COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"1. ‚úÖ Train model in Kaggle (this notebook)\")\n",
    "print(f\"2. üì¶ Create Kaggle Dataset with trained model\")\n",
    "print(f\"3. üè† Download to local application\")\n",
    "print(f\"4. üöÄ Use in production with ANY text source\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
