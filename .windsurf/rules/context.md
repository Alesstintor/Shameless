---
trigger: model_decision
---

# Shameless - Project Context

## Project Mission
Crear una aplicaci√≥n de an√°lisis de sentimientos que permite analizar el perfil completo de un usuario en redes sociales. El usuario proporciona una URL o nombre de usuario, la aplicaci√≥n recopila sus publicaciones y genera un perfil completo de sentimiento usando modelos ML entrenados en Kaggle.

## Core Concept

### üéØ Problema que Resolvemos
**¬øQu√© tipo de persona es este usuario en redes sociales?**

- ¬øEs mayormente positivo o negativo?
- ¬øSobre qu√© temas es m√°s positivo/negativo?
- ¬øC√≥mo ha evolucionado su sentimiento?
- ¬øSu sentimiento afecta su engagement?

### üí° Soluci√≥n
Una aplicaci√≥n local que:
1. Acepta URL o username
2. Scrape el perfil completo del usuario
3. Analiza cada tweet con un modelo entrenado en Kaggle
4. Genera un perfil de sentimiento completo
5. Produce un reporte visual y estad√≠stico

## Workflow Completo

### üìä En Kaggle (Entrenamiento)

```python
# 1. Preparaci√≥n de datos
dataset = load_sentiment_dataset()  # Sentiment140, etc.
train, test = split_data(dataset)

# 2. Entrenamiento
model = train_sentiment_model(
    data=train,
    architecture="bert-base-uncased",
    epochs=3,
    batch_size=16
)

# 3. Evaluaci√≥n
metrics = evaluate(model, test)
print(f"Accuracy: {metrics['accuracy']}")
print(f"F1 Score: {metrics['f1']}")

# 4. Guardar modelo
save_model(model, "sentiment_model_v1")
save_to_kaggle_dataset("shameless-sentiment-models")
```

### üíª En Local (Aplicaci√≥n)

```python
# 1. Usuario inicia an√°lisis
from sentiment_analyser import UserAnalyzer

analyzer = UserAnalyzer()
result = analyzer.analyze("@username", tweets_limit=500)

# 2. Scraping autom√°tico
tweets = scraper.get_user_tweets("username", limit=500)

# 3. Descarga modelo de Kaggle (si no existe)
model = load_model_from_kaggle("sentiment_model_v1")

# 4. Inferencia
sentiments = model.predict_batch(tweets)

# 5. Agregaci√≥n y an√°lisis
profile = aggregate_sentiments(sentiments, tweets)

# 6. Reporte
profile.generate_report("username_report.pdf")
profile.show_interactive_dashboard()
```

## Use Cases Detallados

### 1. An√°lisis de Influencer
**Caso:** Una marca quiere contratar un influencer y necesita saber si su contenido es positivo.

```python
analyzer = UserAnalyzer()
result = analyzer.analyze("@influencer", tweets_limit=1000)

print(result.summary)
# Output:
# Overall Sentiment: Positive (73%)
# Negative tweets: 12%
# Neutral tweets: 15%
# Most positive topics: Technology, Gaming
# Most negative topics: Politics
```

### 2. Monitoreo de Marca Personal
**Caso:** Un profesional quiere analizar c√≥mo se comunica en redes.

```python
result = analyzer.analyze("@professional")
result.show_timeline()  # Muestra evoluci√≥n temporal
result.identify_patterns()  # Identifica patrones

# Sugerencias:
# - Tus tweets sobre "work" son 60% negativos
# - Considera cambiar el tono en temas profesionales
# - Tus tweets m√°s populares son positivos
```

### 3. An√°lisis Comparativo
**Caso:** Comparar el sentimiento de varios usuarios.

```python
users = ["@user1", "@user2", "@user3"]
comparison = analyzer.compare_users(users)

comparison.show_comparison_chart()
comparison.export_excel("comparison.xlsx")
```

### 4. An√°lisis Temporal
**Caso:** Ver c√≥mo ha cambiado el sentimiento de un usuario.

```python
result = analyzer.analyze_timeline(
    "@username",
    start_date="2023-01-01",
    end_date="2024-01-01"
)

result.plot_sentiment_evolution()
# Muestra gr√°fico de l√≠nea con sentimiento a lo largo del tiempo
```

## Technical Context

### Por qu√© Kaggle para Training

**Ventajas:**
- ‚úÖ **GPU gratuita**: P100, T4 (30h/semana)
- ‚úÖ **Datasets p√∫blicos**: Sentiment140, Twitter datasets
- ‚úÖ **Colaboraci√≥n**: Notebooks p√∫blicos
- ‚úÖ **Versionado**: Kaggle Datasets para modelos
- ‚úÖ **Reproducibilidad**: Ambiente consistente

**Flujo:**
```
Kaggle Notebook ‚Üí Train Model ‚Üí Save to Dataset ‚Üí Download Locally
```

### Por qu√© Local Application

**Ventajas:**
- ‚úÖ **Sin l√≠mites de tiempo**: No hay timeout de notebook
- ‚úÖ **Mejor UX**: Streamlit/CLI personalizado
- ‚úÖ **Integraci√≥n**: F√°cil de distribuir
- ‚úÖ **Control**: C√≥digo privado si es necesario

### Model Management

#### Versionado de Modelos
```
Kaggle Dataset: shameless-sentiment-models
‚îú‚îÄ‚îÄ v1.0/
‚îÇ   ‚îú‚îÄ‚îÄ model.pt                  # 250 MB
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer/
‚îÇ   ‚îú‚îÄ‚îÄ config.json
‚îÇ   ‚îî‚îÄ‚îÄ metrics.json             # accuracy: 0.85
‚îÇ
‚îú‚îÄ‚îÄ v1.1/                        # Improved
‚îÇ   ‚îú‚îÄ‚îÄ model.pt                 # 250 MB
‚îÇ   ‚îú‚îÄ‚îÄ metrics.json             # accuracy: 0.87
‚îÇ
‚îî‚îÄ‚îÄ v2.0/                        # New architecture
    ‚îú‚îÄ‚îÄ model.pt                 # 180 MB (distilled)
    ‚îî‚îÄ‚îÄ metrics.json             # accuracy: 0.89
```

#### Local Cache
```
data/models/
‚îú‚îÄ‚îÄ current -> v2.0/            # Symlink al modelo actual
‚îú‚îÄ‚îÄ v1.0/
‚îú‚îÄ‚îÄ v1.1/
‚îî‚îÄ‚îÄ v2.0/
```

## Data Schema

### User Profile Analysis Result

```json
{
  "username": "@elonmusk",
  "analysis_date": "2024-10-18T12:00:00Z",
  "tweets_analyzed": 500,
  "date_range": {
    "start": "2024-09-01",
    "end": "2024-10-18"
  },
  "sentiment_summary": {
    "overall": "positive",
    "positive_pct": 67.2,
    "negative_pct": 18.5,
    "neutral_pct": 14.3,
    "confidence": 0.89
  },
  "sentiment_timeline": [
    {"date": "2024-09-01", "sentiment": 0.65},
    {"date": "2024-09-02", "sentiment": 0.70},
    ...
  ],
  "topic_sentiments": {
    "technology": {"score": 0.82, "positive": 89, "negative": 5},
    "politics": {"score": 0.45, "positive": 32, "negative": 41}
  },
  "engagement_analysis": {
    "positive_tweets_avg_likes": 1250,
    "negative_tweets_avg_likes": 890,
    "sentiment_engagement_correlation": 0.65
  },
  "insights": [
    "User is predominantly positive (67%)",
    "Most negative about politics",
    "Positive tweets get 40% more engagement",
    "Sentiment stable over time"
  ]
}
```

### Tweet Data (Internal)

```json
{
  "id": "1234567890",
  "content": "Original tweet text",
  "clean_content": "preprocessed text",
  "sentiment": {
    "label": "positive",
    "score": 0.95,
    "probabilities": {
      "positive": 0.95,
      "negative": 0.03,
      "neutral": 0.02
    }
  },
  "metadata": {
    "date": "2024-10-18T10:00:00Z",
    "likes": 1200,
    "retweets": 450,
    "replies": 89
  }
}
```

## Configuration

### Kaggle Setup

```bash
# 1. Crear cuenta en Kaggle
# 2. Ir a Account ‚Üí API ‚Üí Create New API Token
# 3. Descargar kaggle.json

# 4. Configurar credenciales
mkdir ~/.kaggle
cp kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json
```

### Local Setup

```env
# .env
KAGGLE_USERNAME=your_username
KAGGLE_KEY=your_key

# Model settings
MODEL_DATASET=your_username/shameless-sentiment-models
MODEL_VERSION=v2.0
AUTO_UPDATE_MODEL=true

# Scraper settings
MAX_TWEETS_PER_USER=500
CACHE_EXPIRY_HOURS=24
RATE_LIMIT=1.0

# Output
REPORTS_DIR=data/reports
CACHE_DIR=data/cache
```

## Common Workflows

### 1. Train New Model in Kaggle

```python
# En Kaggle Notebook

# Load dataset
from kaggle import api
api.dataset_download_files('kazanova/sentiment140')

# Train
model = train_model()

# Save
torch.save(model.state_dict(), 'model.pt')
save_tokenizer(tokenizer, 'tokenizer/')

# Create dataset
!kaggle datasets version -p . -m "Updated model v2.0"
```

### 2. Use Model Locally

```bash
# Download model (autom√°tico si no existe)
python -m sentiment_analyser.models download-model

# Analyze user
python -m sentiment_analyser analyze @username --output report.pdf

# Or use Python API
python
>>> from sentiment_analyser import UserAnalyzer
>>> analyzer = UserAnalyzer()
>>> result = analyzer.analyze("@username")
>>> result.show()
```

### 3. Update Model

```bash
# Download nueva versi√≥n
python -m sentiment_analyser.models update-model --version v2.0

# Validate
python -m sentiment_analyser.models validate-model

# Set as current
python -m sentiment_analyser.models set-current v2.0
```

## Performance Considerations

### Scraping
- **Rate Limiting**: 1 request/segundo (configurable)
- **Cache**: 24h por usuario
- **Batch Size**: 100 tweets por request
- **Timeout**: 30s por request

### Inference
- **Batch Processing**: 32 tweets por batch
- **Device**: CPU por defecto, GPU opcional
- **Max Length**: 512 tokens
- **Quantization**: Opcional para modelos grandes

### Storage
- **Models**: ~250 MB cada uno
- **Cache**: ~10 MB por 500 tweets
- **Reports**: ~2 MB PDF por an√°lisis

## Development Tips

### Testing with Sample Users

```python
# Use public test accounts
TEST_USERS = [
    "@TestUser123",      # Small account (100 tweets)
    "@MediumUser456",    # Medium (1000 tweets)
    "@LargeUser789"      # Large (10000+ tweets)
]

# Quick test
result = analyzer.analyze(TEST_USERS[0], tweets_limit=50)
```

### Debugging Model Issues

```python
# Load model manually
from sentiment_analyser.models import ModelLoader

loader = ModelLoader()
model = loader.load("v2.0")

# Test single prediction
text = "I love this!"
result = model.predict(text)
print(result)  # Should be positive
```

### Monitoring Performance

```python
import time

start = time.time()
result = analyzer.analyze("@username", tweets_limit=500)
duration = time.time() - start

print(f"Analysis took: {duration:.2f}s")
print(f"Tweets/second: {500/duration:.1f}")
```

## Resources

### Kaggle Datasets for Training
- [Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140) - 1.6M tweets
- [Twitter Sentiment](https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis) - Entity-level
- [IMDB Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) - For transfer learning

### Pre-trained Models
- `bert-base-uncased` - General purpose
- `distilbert-base-uncased` - Faster, smaller
- `cardiffnlp/twitter-roberta-base-sentiment` - Twitter-specific

### Tools
- **Kaggle API**: [Documentation](https://www.kaggle.com/docs/api)
- **snscrape**: [GitHub](https://github.com/JustAnotherArchivist/snscrape)
- **transformers**: [HuggingFace Docs](https://huggingface.co/docs/transformers)
- **Streamlit**: [Documentation](https://docs.streamlit.io/)

## Roadmap

### MVP (Current Phase)
- [x] Project structure
- [ ] Kaggle notebook template
- [ ] Model download from Kaggle
- [ ] User scraping
- [ ] Basic sentiment analysis
- [ ] CLI interface

### Phase 2
- [ ] Streamlit web UI
- [ ] PDF report generation
- [ ] Temporal analysis
- [ ] Topic analysis
- [ ] Model auto-update

### Phase 3
- [ ] Multi-user comparison
- [ ] Real-time monitoring
- [ ] Email alerts
- [ ] Dashboard analytics
- [ ] API REST

### Phase 4
- [ ] Multi-platform (Instagram, Reddit)
- [ ] Image analysis
- [ ] Emotion detection
- [ ] Influencer metrics
